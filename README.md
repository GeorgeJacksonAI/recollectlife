# Life Story Game â€“ AI Interviewer

An AI-powered interviewer that transforms personal life stories into meaningful board game narratives. Built with React, Vite, Tailwind CSS (frontend) and Python serverless functions + Google Gemini (backend).

The AI conducts a compassionate 6-question interview across 7 storytelling routes to extract core motivations, turning points, and emotional themes, then synthesizes a structured narrative with title, chapters, and key moments.

## ğŸš€ Tech Stack

- **Frontend**: React 19, Vite 7, Tailwind CSS 4
- **Backend**: Python 3.9+ serverless functions (Vercel)
- **AI Model**: Google Gemini (fallback cascade: 2.5-flash â†’ 2.0-flash â†’ lite variants)
- **Architecture**: Stateless REST API, client-managed conversation state
- **Testing**: Pytest (backend), Vitest + React Testing Library (frontend)
- **Deployment**: Vercel (automatic from git push)

## ğŸ“‹ Features

- ğŸ­ **7 Storytelling Routes**: Chronological, Thematic, Anecdotal, Interview, Reflective, Legacy, Custom
- ğŸ“– **6-Phase Interview**: GREETING â†’ ROUTE_SELECTION â†’ 5 QUESTIONS â†’ SYNTHESIS
- âœ¨ **AI Fallback Cascade**: Automatic retry across 6 Gemini models on rate limits
- ğŸ”’ **Stateless Architecture**: No server-side sessions, scales horizontally
- ğŸ’¬ **Context-Aware**: Client sends full conversation history each request
- ğŸ¨ **Modern UI**: Dark mode chat interface with phase indicators
- âš¡ **Fast**: Serverless functions with 30s timeout, optimized fallback
- ğŸ›¡ï¸ **Production-Ready**: Input validation, error handling, comprehensive tests

## ğŸ“ Project Structure

```
/
â”œâ”€â”€ api/                      # Vercel serverless functions (Python)
â”‚   â”œâ”€â”€ chat.py              # POST /api/chat - main AI endpoint
â”‚   â”œâ”€â”€ model_status.py      # GET /api/model-status - model info
â”‚   â”œâ”€â”€ health.py            # GET /api/health - health check
â”‚   â””â”€â”€ ai_fallback.py       # Pure fallback logic (tested)
â”œâ”€â”€ frontend/                 # React + Vite frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx          # Main chat UI (stateless)
â”‚   â”‚   â”œâ”€â”€ __tests__/       # Vitest component tests
â”‚   â”‚   â””â”€â”€ test/setup.js    # Test configuration
â”‚   â”œâ”€â”€ vite.config.js       # Build config (no proxy needed)
â”‚   â””â”€â”€ package.json         # Frontend dependencies + test scripts
â”œâ”€â”€ src/                      # Shared Python logic
â”‚   â”œâ”€â”€ conversation.py      # ConversationState, phase definitions
â”‚   â””â”€â”€ ...
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ python/              # Backend unit tests (37 passing)
â”œâ”€â”€ vercel.json              # Vercel deployment config
â”œâ”€â”€ requirements.txt         # Python deps for Vercel runtime
â””â”€â”€ .env.example             # Environment variable template
```

## Prerequisites

- **Node.js** 18+
- **Python** 3.9+
- **Vercel CLI** (optional): `npm install -g vercel`
- **Google AI Studio** account: [Get API key](https://aistudio.google.com/app/apikey)

## ğŸ”§ Setup

### 1. Clone & Configure

```bash
git clone <repo-url>
cd openai_chatbot
```

Create `.env` (NEVER commit):
```bash
GEMINI_API_KEY="your_google_gemini_api_key_here"
```

### 2. Install Dependencies

**Frontend:**
```bash
cd frontend && npm install
```

**Backend (tests):**
```bash
conda create -y -n chatbot python=3.10
conda activate chatbot
pip install -r backend/requirements.txt
```

## ğŸ§ª Testing

**Backend:** âœ… 37/37 passing
```bash
conda activate chatbot
pytest tests/python/ -v
```

**Frontend:**
```bash
cd frontend && npm test
```

## ğŸš€ Running Locally

**Vercel Dev (Recommended):**
```bash
vercel dev
# Frontend + API at http://localhost:3000
```

**Separate Servers (Legacy):**
```bash
# Terminal 1
cd frontend && npm run dev

# Terminal 2 (deprecated Flask)
conda activate chatbot
python backend/api.py
```

## ğŸ“¡ API Endpoints

### `POST /api/chat`
```json
{
  "messages": [{"role": "user", "content": "Hello"}],
  "phase": "GREETING",
  "selected_route": "1"
}
```

### `GET /api/model-status`
Returns fallback cascade info.

### `GET /api/health`
Health check.

## ğŸš¢ Vercel Deployment

### 1. Connect Repository
- Visit [vercel.com](https://vercel.com)
- Import GitHub repository

### 2. Configure Project
- **Build Command:** `cd frontend && npm install && npm run build`
- **Output Directory:** `frontend/dist`
- **Root Directory:** `./` (leave empty)

### 3. Environment Variables
Add in Vercel dashboard:
- `GEMINI_API_KEY`: Your Google AI Studio key

### 4. Deploy
```bash
vercel --prod
```

Auto-deploys on git push to `main`.

## ğŸ”’ Security

- âœ… API keys server-side only (Vercel env)
- âœ… Input validation (50K char limit)
- âœ… Never commit `.env`
- âœ… CORS headers in serverless functions

## ğŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| **401 Auth Error** | Verify `GEMINI_API_KEY` in Vercel env vars |
| **429 Rate Limit** | Normal - fallback retries next model |
| **Empty responses** | Check Vercel function logs |
| **Build fails** | Delete `node_modules`, reinstall |

## ğŸ“¦ Key Dependencies

**Backend:** `google-generativeai`, `pytest`  
**Frontend:** React 19, Vite 7, Vitest, Tailwind CSS 4

## ğŸ¨ Customization

**Change Models:**
```bash
# In Vercel env vars
GEMINI_MODELS=gemini-2.5-flash,gemini-1.5-pro
```

**Edit Questions:** Modify `src/conversation.py` `INTERVIEW_PHASES`

**Adjust Timeout:** Edit `vercel.json` `maxDuration`

## ğŸ¤ Contributing

Focus areas: frontend tests, interview optimization, UI/UX, performance

## ğŸ“ License

MIT License

## ğŸ”— Resources

- [Google AI Studio](https://aistudio.google.com/)
- [Vercel Docs](https://vercel.com/docs)
- [Gemini API Docs](https://ai.google.dev/docs)

---

**Built with â¤ï¸ for preserving life stories through AI**

